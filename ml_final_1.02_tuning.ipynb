{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNIEs8mpcrNM83IJRLLnMgo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Set-up"],"metadata":{"id":"WAEHYIdvwQBf"}},{"cell_type":"markdown","source":["Deliverables:\n","\n","1-You must create a simple web API to predict a user's BMI in real-time. You can also use webcam input. The goal is to use one of the pre-trained image models (e.g. VGG Face), fine-tune with the provided data, and deploy via jupyter notebook, streamlit, flask or any other simple restful api's.\n","\n","2-10 pages of the write-up about your implementation.\n","\n","3-10 mins presentation or live demo in the final lecture.\n","\n","Our goal is to beat the performance metrics provided in the paper."],"metadata":{"id":"xK2j-u-kLuID"}},{"cell_type":"code","source":["import os\n","# Load the Drive helper and mount\n","from google.colab import drive\n","# This will prompt for authorization.\n","drive.mount('/content/drive/')\n","path_gdrive = '/content/drive/MyDrive/Colab Datasets/ML/BMI'\n","os.chdir(path_gdrive)\n","print(os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llKxwaWIVPAi","executionInfo":{"status":"ok","timestamp":1684182877756,"user_tz":300,"elapsed":1731,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}},"outputId":"a95efaee-0e97-4e00-ba43-e045c1ea11b6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/Colab Datasets/ML/BMI\n"]}]},{"cell_type":"code","source":["# read csv file\n","data_path = '/content/drive/MyDrive/Colab Datasets/ML/BMI/all_data.csv'\n","bmi = pd.read_csv(data_path)"],"metadata":{"id":"Lqa7nWVpXkOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"GriKxF34LpE_","executionInfo":{"status":"ok","timestamp":1684183065187,"user_tz":300,"elapsed":1563,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}}},"outputs":[],"source":["import sys\n","import os\n","import json\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","pd.set_option('display.max_rows', 100)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_colwidth', 500)"],"metadata":{"id":"-hz4938yYCqi","executionInfo":{"status":"ok","timestamp":1684183065188,"user_tz":300,"elapsed":8,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras"],"metadata":{"id":"WfR0IxTuHQbV","executionInfo":{"status":"ok","timestamp":1684183086093,"user_tz":300,"elapsed":3230,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(\"TensorFlow version:\", tf.__version__)\n","print(\"Keras version:\", keras.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2ONrBZjImrv","executionInfo":{"status":"ok","timestamp":1684183111591,"user_tz":300,"elapsed":3,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}},"outputId":"4a57fecf-be38-4704-868e-164a48cf8e0f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.12.0\n","Keras version: 2.12.0\n"]}]},{"cell_type":"code","source":["! pip install keras_vggface"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEa7Fva1I2ds","executionInfo":{"status":"ok","timestamp":1684183157421,"user_tz":300,"elapsed":5260,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}},"outputId":"a11a9076-64f0-4332-ebb2-503ec1d9b764"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_vggface\n","  Downloading keras_vggface-0.6-py3-none-any.whl (8.3 kB)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.22.4)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.10.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (3.8.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (8.4.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (2.12.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (1.16.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras_vggface) (6.0)\n","Installing collected packages: keras_vggface\n","Successfully installed keras_vggface-0.6\n"]}]},{"cell_type":"markdown","source":["### Prepare Keras"],"metadata":{"id":"TLgYq3sDwODL"}},{"cell_type":"code","source":["# !python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQ9nBJii6Bo3","executionInfo":{"status":"ok","timestamp":1684182432540,"user_tz":300,"elapsed":161,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}},"outputId":"a3757c0c-51a4-4e80-9932-06115aefd6f6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.11\n"]}]},{"cell_type":"code","source":["# https://stackoverflow.com/questions/68862735/keras-vggface-no-module-named-keras-engine-topology\n","#! pip install git+https://github.com/rcmalli/keras-vggface.git\n","! pip install keras_applications --no-deps\n","\n","filename = \"/usr/local/lib/python3.10/dist-packages/keras_vggface/models.py\"\n","text = open(filename).read()\n","open(filename, \"w+\").write(text.replace('keras.engine.topology', 'tensorflow.keras.utils'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMPvk0m13k-z","executionInfo":{"status":"ok","timestamp":1684183224116,"user_tz":300,"elapsed":1559,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}},"outputId":"4481f44f-62c4-42aa-9acf-3f337ce7a0c0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_applications\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras_applications\n","Successfully installed keras_applications-1.0.8\n"]},{"output_type":"execute_result","data":{"text/plain":["20951"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## Extact Features\n","\n","1. Read images with Kreas API: https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/"],"metadata":{"id":"ljYslsIVwY_1"}},{"cell_type":"code","source":["bmi.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"jnffl-2HwcFA","executionInfo":{"status":"ok","timestamp":1684182805804,"user_tz":300,"elapsed":169,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}},"outputId":"487d50e8-6626-4431-cf15-ee94dbd30635"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           name                      path        bmi gender  is_training  \\\n","0     img_0.bmp     Data/Images/img_0.bmp  34.207396   Male            1   \n","1     img_1.bmp     Data/Images/img_1.bmp  26.453720   Male            1   \n","2    img_10.bmp    Data/Images/img_10.bmp  38.732782   Male            1   \n","3   img_100.bmp   Data/Images/img_100.bmp  29.834105   Male            1   \n","4  img_1000.bmp  Data/Images/img_1000.bmp  42.240827   Male            1   \n","\n","  imgae_type  \n","0        bmp  \n","1        bmp  \n","2        bmp  \n","3        bmp  \n","4        bmp  "],"text/html":["\n","  <div id=\"df-40911557-d928-443d-bee0-fa183f2df540\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>path</th>\n","      <th>bmi</th>\n","      <th>gender</th>\n","      <th>is_training</th>\n","      <th>imgae_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>img_0.bmp</td>\n","      <td>Data/Images/img_0.bmp</td>\n","      <td>34.207396</td>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>bmp</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>img_1.bmp</td>\n","      <td>Data/Images/img_1.bmp</td>\n","      <td>26.453720</td>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>bmp</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>img_10.bmp</td>\n","      <td>Data/Images/img_10.bmp</td>\n","      <td>38.732782</td>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>bmp</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>img_100.bmp</td>\n","      <td>Data/Images/img_100.bmp</td>\n","      <td>29.834105</td>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>bmp</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>img_1000.bmp</td>\n","      <td>Data/Images/img_1000.bmp</td>\n","      <td>42.240827</td>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>bmp</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40911557-d928-443d-bee0-fa183f2df540')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-40911557-d928-443d-bee0-fa183f2df540 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-40911557-d928-443d-bee0-fa183f2df540');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["train = bmi[bmi.is_training == 1]\n","val = bmi[bmi.is_training != 1]"],"metadata":{"id":"rpyexuX8wcBw","executionInfo":{"status":"ok","timestamp":1684182808252,"user_tz":300,"elapsed":253,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from keras_vggface.vggface import VGGFace\n","from keras.models import Model\n","\n","# Initialize a model for feature extraction\n","vggface = VGGFace()"],"metadata":{"id":"qbn6LKsMwqVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Match outputs to fc6 features\n","model = Model(inputs=vggface.input, outputs=vggface.get_layer('fc6').output)\n","\n","# Define layer name for feature extraction\n","layer_name = 'fc6'"],"metadata":{"id":"TIlI8Z5TwqTF","executionInfo":{"status":"ok","timestamp":1684183495050,"user_tz":300,"elapsed":347,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# example of loading an image with the Keras API\n","from keras.preprocessing.image import *\n","\n","def extract_features(img_path):\n","  if os.path.exists(img_path):\n","    img = load_img(img_path, target_size=(224, 224))\n","    x = img_to_array(img)\n","    x = np.expand_dims(x, axis=0) # Add one dimension (channel)\n","    x = utils.preprocess_input(x, version=1)\n","    features = model.predict(x)\n","    return features.flatten( )\n","  else:\n","    return None"],"metadata":{"id":"6wce4PSBwqQS","executionInfo":{"status":"ok","timestamp":1684183780478,"user_tz":300,"elapsed":493,"user":{"displayName":"Han Jiang","userId":"07380456769307295080"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gE-HUKk5LSme"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note:\n","\n","1. Transfer Learning. https://medium.com/@leosimmons/estimating-body-mass-index-from-face-images-using-keras-and-transfer-learning-de25e1bc0212"],"metadata":{"id":"HwxPgof72dIU"}},{"cell_type":"code","source":[],"metadata":{"id":"HBTD3L_R2fFT"},"execution_count":null,"outputs":[]}]}