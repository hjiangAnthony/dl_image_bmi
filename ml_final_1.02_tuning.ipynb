{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WAEHYIdvwQBf",
    "tags": []
   },
   "source": [
    "# MSCA ML Final Project: Face-to-BMI\n",
    "# Part 2: Image Embedding and Basic VGG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xK2j-u-kLuID"
   },
   "source": [
    "Deliverables:\n",
    "\n",
    "1-You must create a simple web API to predict a user's BMI in real-time. You can also use webcam input. The goal is to use one of the pre-trained image models (e.g. VGG Face), fine-tune with the provided data, and deploy via jupyter notebook, streamlit, flask or any other simple restful api's.\n",
    "\n",
    "2-10 pages of the write-up about your implementation.\n",
    "\n",
    "3-10 mins presentation or live demo in the final lecture.\n",
    "\n",
    "Our goal is to beat the performance metrics provided in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1731,
     "status": "ok",
     "timestamp": 1684182877756,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "llKxwaWIVPAi",
    "outputId": "a95efaee-0e97-4e00-ba43-e045c1ea11b6"
   },
   "outputs": [],
   "source": [
    "''' # colab mount\n",
    "import os\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive/')\n",
    "path_gdrive = '/content/drive/MyDrive/Colab Datasets/ML/BMI'\n",
    "os.chdir(path_gdrive)\n",
    "print(os.getcwd())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/data/ml/BMI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Google Bucket\n",
    "bucket_path = 'gs://msca-sp23-bucket/ml_data'\n",
    "file = 'BMI-20230313T174553Z-001.zip'\n",
    "runtime_path = '/home/jupyter/data/ml/BMI'\n",
    "\n",
    "os.chdir(runtime_path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lqa7nWVpXkOp",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender</th>\n",
       "      <th>is_training</th>\n",
       "      <th>name</th>\n",
       "      <th>imgae_type</th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.207396</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_0.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_0.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.453720</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_1.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_1.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.967561</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_2.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_2.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.044766</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_3.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>3</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_3.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.845588</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_6.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>6</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_6.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bmi  gender  is_training       name imgae_type  id   \n",
       "0  34.207396    Male            1  img_0.bmp        bmp   0  \\\n",
       "1  26.453720    Male            1  img_1.bmp        bmp   1   \n",
       "2  34.967561  Female            1  img_2.bmp        bmp   2   \n",
       "3  22.044766  Female            1  img_3.bmp        bmp   3   \n",
       "4  25.845588  Female            1  img_6.bmp        bmp   6   \n",
       "\n",
       "                                         path  \n",
       "0  /home/jupyter/data/ml/BMI/Images/img_0.bmp  \n",
       "1  /home/jupyter/data/ml/BMI/Images/img_1.bmp  \n",
       "2  /home/jupyter/data/ml/BMI/Images/img_2.bmp  \n",
       "3  /home/jupyter/data/ml/BMI/Images/img_3.bmp  \n",
       "4  /home/jupyter/data/ml/BMI/Images/img_6.bmp  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file\n",
    "bmi = pd.read_csv(runtime_path + '/all_data.csv')\n",
    "bmi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3230,
     "status": "ok",
     "timestamp": 1684183086093,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "WfR0IxTuHQbV",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 02:53:04.282700: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 02:53:04.350493: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 02:53:04.351871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 02:53:05.307676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684183111591,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "x2ONrBZjImrv",
    "outputId": "4a57fecf-be38-4704-868e-164a48cf8e0f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "Keras version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5260,
     "status": "ok",
     "timestamp": 1684183157421,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "wEa7Fva1I2ds",
    "outputId": "a11a9076-64f0-4332-ebb2-503ec1d9b764"
   },
   "outputs": [],
   "source": [
    "#!pip install keras_vggface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TLgYq3sDwODL",
    "tags": []
   },
   "source": [
    "### Prepare Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1684182432540,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "vQ9nBJii6Bo3",
    "outputId": "a3757c0c-51a4-4e80-9932-06115aefd6f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.11\n"
     ]
    }
   ],
   "source": [
    "# !python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1559,
     "status": "ok",
     "timestamp": 1684183224116,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "LMPvk0m13k-z",
    "outputId": "4481f44f-62c4-42aa-9acf-3f337ce7a0c0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # @https://stackoverflow.com/questions/68862735/keras-vggface-no-module-named-keras-engine-topology\n",
    "#! pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "#! pip install keras_applications --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/opt/conda/envs/nlp/lib/python3.10/site-packages/keras_vggface/models.py\"\n",
    "# text = open(filename).read()\n",
    "# open(filename, \"w+\").write(text.replace('keras.engine.topology', 'keras.utils.layer_utils'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install opencv-python\n",
    "# ! pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras vggface model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Flatten, Dense, Input, Dropout, Activation, BatchNormalization\n",
    "\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Model\n",
    "# example of loading an image with the Keras API\n",
    "# since 2021 tensorflow updated the package and moved model directory\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import keras_vggface.utils as utils\n",
    "\n",
    "# image manipulation\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# face alignment\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# model metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# common packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy-to-use metrics\n",
    "def rmse(x,y):\n",
    "    return np.sqrt(mean_squared_error(x,y))\n",
    "\n",
    "def mae(x,y):\n",
    "    return mean_absolute_error(x,y)\n",
    "\n",
    "def auc(label, pred):\n",
    "    return roc_auc_score(label, pred)\n",
    "\n",
    "# image feature extraction\n",
    "def imgs_to_array(img_paths, version=1):\n",
    "    ''' extract features from all images and convert to multi-dimensional array\n",
    "    Takes:\n",
    "        img_path: str\n",
    "        version: int\n",
    "    Returns:\n",
    "        np.array\n",
    "    '''\n",
    "    imgs = []\n",
    "    for img_path in img_paths: # += is equivalent to extend @http://noahsnail.com/2020/06/17/2020-06-17-python%E4%B8%ADlist%E7%9A%84append,%20extend%E5%8C%BA%E5%88%AB/\n",
    "        imgs += [img_to_array(img_path, version)]\n",
    "    return np.concatenate(imgs)\n",
    "\n",
    "def process_array(arr, version):\n",
    "    '''array processing (resize)\n",
    "    Takes: arr: np.array\n",
    "    Returns: np.array\n",
    "    '''\n",
    "    img = cv2.resize(arr, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = utils.preprocess_input(img, version=version)\n",
    "    return img\n",
    "\n",
    "def img_to_array(img_path, version):\n",
    "    '''conver a SINGLE image to array\n",
    "    Takes: img_path: str\n",
    "    Returns: np.array\n",
    "    '''\n",
    "    img = image.load_img(img_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = process_array(img, version)\n",
    "    return img\n",
    "\n",
    "def crop_img(img,x,y,w,h):\n",
    "    '''crop image\n",
    "    Takes: img: np.array\n",
    "           x,y,w,h: int\n",
    "    Returns: np.array\n",
    "    '''\n",
    "    return img[y:y+h,x:x+w,:]\n",
    "\n",
    "def img_data_generator(data, version = 1): #replace function name later\n",
    "    \"\"\"data input pipeline\n",
    "    Args:\n",
    "    @data: dataframe\n",
    "    \"\"\"\n",
    "    sex_map = {'Male':1, 'Female':0}\n",
    "    loop = True\n",
    "    \n",
    "    while loop:\n",
    "        x = imgs_to_array(data['path'], version)\n",
    "        y = [data['bmi'].values, data['gender'].map(lambda i: sex_map.get(i,0)).values]\n",
    "        features = (x,y)\n",
    "        yield features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a prediction class\n",
    "\n",
    "class FacePrediction(object):\n",
    "\n",
    "    def __init__(self, img_path, mode_type='vgg16', sex_thresh = 0.05):\n",
    "        self.model_type = mode_type\n",
    "        self.img_path = img_path\n",
    "        self.detector = MTCNN()\n",
    "        self.sex_thres = sex_thresh\n",
    "        if mode_type in ['vgg16', 'vgg16_fc6']: # we might use other models, but in that case we need to just version input\n",
    "            self.version = 1\n",
    "        else:\n",
    "            self.version = 2\n",
    "\n",
    "    def define_model(self, hidden_dim = 128, drop_rate=0.0, freeze_backbone = True): # replace function name later\n",
    "        ''' initialize the vgg model\n",
    "        Reference:\n",
    "            @https://zhuanlan.zhihu.com/p/53116610\n",
    "            @https://zhuanlan.zhihu.com/p/26934085\n",
    "        '''\n",
    "        if self.model_type == 'vgg16_fc6':\n",
    "            vgg_model = VGGFace(model = 'vgg16', include_top=True, input_shape=(224, 224, 3))\n",
    "            last_layer = vgg_model.get_layer('fc6').output\n",
    "            flatten = Activation('relu')(last_layer)\n",
    "        else:\n",
    "            vgg_model = VGGFace(model = self.model_type, include_top=False, input_shape=(224, 224, 3))\n",
    "            last_layer = vgg_model.output\n",
    "            flatten = Flatten()(last_layer)\n",
    "        \n",
    "        if freeze_backbone: # free the vgg layers to fine-tune\n",
    "            for layer in vgg_model.layers:\n",
    "                layer.trainable = False\n",
    "                \n",
    "        def model_init(flatten, name):\n",
    "            x = Dense(hidden_dim, name=name + '_fc1')(flatten)\n",
    "            x = BatchNormalization(name = name + '_bn1')(x)\n",
    "            x = Activation('relu', name = name+'_act1')(x)\n",
    "            x = Dropout(drop_rate)(x)\n",
    "            x = Dense(hidden_dim, name=name + '_fc2')(x)\n",
    "            x = BatchNormalization(name = name + '_bn2')(x)\n",
    "            x = Activation('relu', name = name+'_act2')(x)\n",
    "            x = Dropout(drop_rate)(x)\n",
    "            return x\n",
    "        \n",
    "        x = model_init(flatten, name = 'bmi')\n",
    "        bmi_pred = Dense(1, activation='linear', name='bmi')(x)\n",
    "        \n",
    "        x = model_init(flatten, name = 'sex')\n",
    "        sex_pred = Dense(1, activation = 'sigmoid', name = 'sex')(x)\n",
    "\n",
    "        custom_vgg_model = Model(vgg_model.input, [bmi_pred, sex_pred])\n",
    "        custom_vgg_model.compile('adam', \n",
    "                                 {'bmi':'mae', 'sex':'binary_crossentropy'},\n",
    "                                 {'sex': 'accuracy'}, \n",
    "                                 loss_weights={'bmi': 0.8, 'sex':0.2})\n",
    "\n",
    "        self.model = custom_vgg_model\n",
    "\n",
    "    def train(self, train_data, val_data, bs, epochs, callbacks):\n",
    "        ''' train the model\n",
    "        Notes: 1/ we already have labeled images for training, so we won't need to consider epochs and batch_size\n",
    "        Takes: \n",
    "            train_data: dataframe\n",
    "            val_data: dataframe\n",
    "            bs: int, batch size\n",
    "            epochs: int, number of epochs\n",
    "            callbacks: list, callbacks\n",
    "        '''\n",
    "        train_gen = img_data_generator(train_data, self.version)\n",
    "        val_gen = img_data_generator(val_data, self.version)\n",
    "        self.model.fit_generator(train_gen, len(train_data)//bs, epochs=epochs,\n",
    "                                 validation_data=val_gen, validation_steps=len(val_data)//bs,\n",
    "                                 callbacks=callbacks)\n",
    "    \n",
    "    def evaluate_perf(self, val_data):\n",
    "        img_paths = val_data['path'].values\n",
    "        arr = imgs_to_array(img_paths, self.version)\n",
    "        bmi, sex = self.model.predict(arr)\n",
    "        metrics = {'bmi_mae':mae(bmi[:,0], val_data.bmi.values), \n",
    "                   'sex_auc':auc(val_data.gender, sex[:,0])}\n",
    "        return metrics\n",
    "    \n",
    "    def detect_faces(self, img_path, confidence):\n",
    "        img = image.load_img(img_path)\n",
    "        img = image.img_to_array(img)\n",
    "        box = self.detector.detect_faces(img)\n",
    "        box = [i for i in box if i['confidence'] > confidence]\n",
    "        res = [crop_img(img, *i['box']) for i in box]\n",
    "        res = [process_array(i, self.version) for i in res]\n",
    "        return box, res\n",
    "    \n",
    "    def predict(self, img_dir, show_img = False):\n",
    "        if os.path.isdir(img_dir): # check if this is a directory\n",
    "            imgs = os.listdir(img_dir)\n",
    "            arr = imgs_to_array(imgs, img_dir, self.version)\n",
    "        else:\n",
    "            img_path = img_dir\n",
    "            arr = img_to_array(img_path, self.version)\n",
    "        preds = self.model.predict(arr)\n",
    "        \n",
    "        if show_img and os.path.isdir(img_dir):\n",
    "            bmi, age, sex = preds\n",
    "            num_plots = len(imgs)\n",
    "            ncols = 5\n",
    "            nrows = int((num_plots - 0.1) // ncols + 1)\n",
    "            fig, axs = plt.subplots(nrows, ncols)\n",
    "            fig.set_size_inches(3 * ncols, 3 * nrows)\n",
    "            for i, img in enumerate(imgs):\n",
    "                col = i % ncols\n",
    "                row = i // ncols\n",
    "                axs[row, col].imshow(plt.imread(os.path.join(img_dir,img)))\n",
    "                axs[row, col].axis('off')\n",
    "                axs[row, col].set_title('BMI: {:3.1f} SEX: {:2.1f}'.format(bmi[i,0], sex[i,0]), fontsize = 12)\n",
    "        \n",
    "        return preds\n",
    "\n",
    "    def predict_df(self, img_dir):\n",
    "        assert os.path.isdir(img_dir), 'input must be directory'\n",
    "        fnames = os.listdir(img_dir)\n",
    "        bmi, sex = self.predict(img_dir)\n",
    "        results = pd.DataFrame({'img':fnames, 'bmi':bmi[:,0], 'sex':sex[:,0]})\n",
    "        results['sex_prob'] = results['sex']\n",
    "        results['sex'] = results['sex'].map(lambda i: 'Male' if i > self.sex_thresh else 'Female')\n",
    "        return results\n",
    "    \n",
    "    def predict_faces(self, img_path, show_img = True, color = \"white\", fontsize = 12, \n",
    "                      confidence = 0.95, fig_size = (16,12)):\n",
    "        \n",
    "        assert os.path.isfile(img_path), 'only single image is supported'\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        boxes, faces = self.detect_faces(img_path, confidence)\n",
    "        preds = [self.model.predict(face) for face in faces]\n",
    "        \n",
    "        if show_img:\n",
    "            # Create figure and axes\n",
    "            num_box = len(boxes)\n",
    "            fig,ax = plt.subplots()\n",
    "            fig.set_size_inches(fig_size)\n",
    "            # Display the image\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            # Create a Rectangle patch\n",
    "            for idx, box in enumerate(boxes):\n",
    "                bmi, age, sex = preds[idx]\n",
    "                box_x, box_y, box_w, box_h = box['box']\n",
    "                rect = patches.Rectangle((box_x, box_y), box_w, box_h, linewidth=1,edgecolor='yellow',facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(box_x, box_y, \n",
    "                        'BMI:{:3.1f}\\nSEX:{:s}'.format(bmi[0,0], age[0,0], 'M' if sex[0,0] > self.sex_thresh else 'F'),\n",
    "                       color = color, fontsize = fontsize)\n",
    "            plt.show()\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1684183780478,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "6wce4PSBwqQS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "img_dir = '/home/jupyter/data/ml/BMI'\n",
    "es = EarlyStopping(patience=3)\n",
    "ckp = ModelCheckpoint(model_dir, save_best_only=True, save_weights_only=True, verbose=1)\n",
    "tb = TensorBoard('./tb/%s'%(model_id))\n",
    "callbacks = [es, ckp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ljYslsIVwY_1"
   },
   "source": [
    "## Extact Features\n",
    "\n",
    "1. Read images with Kreas API: https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fixing a bug here: https://github.com/rcmalli/keras-vggface/issues/73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1684182805804,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "jnffl-2HwcFA",
    "outputId": "487d50e8-6626-4431-cf15-ee94dbd30635",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender</th>\n",
       "      <th>is_training</th>\n",
       "      <th>name</th>\n",
       "      <th>imgae_type</th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.207396</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_0.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_0.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.453720</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>img_1.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_1.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.967561</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_2.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_2.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.044766</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_3.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>3</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_3.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.845588</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>img_6.bmp</td>\n",
       "      <td>bmp</td>\n",
       "      <td>6</td>\n",
       "      <td>/home/jupyter/data/ml/BMI/Images/img_6.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bmi  gender  is_training       name imgae_type  id   \n",
       "0  34.207396    Male            1  img_0.bmp        bmp   0  \\\n",
       "1  26.453720    Male            1  img_1.bmp        bmp   1   \n",
       "2  34.967561  Female            1  img_2.bmp        bmp   2   \n",
       "3  22.044766  Female            1  img_3.bmp        bmp   3   \n",
       "4  25.845588  Female            1  img_6.bmp        bmp   6   \n",
       "\n",
       "                                         path  \n",
       "0  /home/jupyter/data/ml/BMI/Images/img_0.bmp  \n",
       "1  /home/jupyter/data/ml/BMI/Images/img_1.bmp  \n",
       "2  /home/jupyter/data/ml/BMI/Images/img_2.bmp  \n",
       "3  /home/jupyter/data/ml/BMI/Images/img_3.bmp  \n",
       "4  /home/jupyter/data/ml/BMI/Images/img_6.bmp  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1684182808252,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "rpyexuX8wcBw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = bmi[bmi.is_training == 1]\n",
    "val = bmi[bmi.is_training != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qbn6LKsMwqVZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_vgg16.h5\n",
      "580070376/580070376 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize a model for feature extraction\n",
    "vggface = VGGFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1684183495050,
     "user": {
      "displayName": "Han Jiang",
      "userId": "07380456769307295080"
     },
     "user_tz": 300
    },
    "id": "TIlI8Z5TwqTF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Match outputs to fc6 features\n",
    "# model = Model(inputs=vggface.input, outputs=vggface.get_layer('fc6').output)\n",
    "\n",
    "# # Define layer name for feature extraction\n",
    "# layer_name = 'fc6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "gE-HUKk5LSme",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 310ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -1.4681633,  -0.5275203, -22.067028 , ..., -17.18492  ,\n",
       "       -11.092118 ,  -0.3551265], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = '/home/jupyter/data/ml/BMI/Images/img_0.bmp'\n",
    "# extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HwxPgof72dIU"
   },
   "source": [
    "Note:\n",
    "\n",
    "1. Transfer Learning. https://medium.com/@leosimmons/estimating-body-mass-index-from-face-images-using-keras-and-transfer-learning-de25e1bc0212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNIEs8mpcrNM83IJRLLnMgo",
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
